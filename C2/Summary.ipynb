{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Summary.ipynb","provenance":[],"authorship_tag":"ABX9TyOHTAb9t/lTdUH6zQJT17C2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Introduction\n","This is a summary of the course's topics which highlights the elements of the course present in the official checklist of Tensorflow Exam. We will follow the course and do not focus on the storyline of each topic, something we have already done in the previous scripts, but we are going to pay attention on the single requirements of the checklist and examine them fully. "],"metadata":{"id":"NdsT9b_NqV4C"}},{"cell_type":"markdown","source":["#Part 1: Tensorflow Developer Skills\n","You need to demonstrate that you understand how to develop software programs using TensorFlow and\n","that you can find the information you need to work as an ML practitioner."],"metadata":{"id":"Jqz0g-nwruaF"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__) # check the version (should be 2.x+)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjiuWVn3EAbp","executionInfo":{"status":"ok","timestamp":1646751937100,"user_tz":-60,"elapsed":3264,"user":{"displayName":"tiziano medas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12272265020738565914"}},"outputId":"b17b940d-51a9-447d-9a6d-fd24e77d7595"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"markdown","source":["## 1.1\n","Know how to program in Python, resolve Python issues, and compile and run Python programs\tin PyCharm.\n","**TODO**\n"],"metadata":{"id":"CK3Fd-e5cCXC"}},{"cell_type":"markdown","source":["## 1.2\n","Know how to find information about TensorFlow APIs, including how to find guides and API references on tensorflow.org.\n","**DONE +-**\n"],"metadata":{"id":"-cKVcKJSciIf"}},{"cell_type":"markdown","source":["## 1.3\n","Know how to debug, investigate, and solve error messages from the TensorFlow API.\n","**DONE +-**\n"],"metadata":{"id":"UVOg3tkfcs6G"}},{"cell_type":"markdown","source":["## 1.4\n","Know how to search beyond tensorflow.org, as and when necessary, to solve your TensorFlow\tquestions.\n","**DONE+-**"],"metadata":{"id":"Uf706NjdcyYH"}},{"cell_type":"markdown","source":["## 1.5\n","Know how to create ML models using TensorFlow where the model size is reasonable for the problem being solved.\n","**DONE +-**\n"],"metadata":{"id":"GcyuuPz8c4j3"}},{"cell_type":"markdown","source":["## 1.6\n","Know how to save ML models and check the model file size.\n","**DONE +-**\n"],"metadata":{"id":"PFReUe6Rc-x2"}},{"cell_type":"markdown","source":["There are two ways to save a model in TensorFlow:\n","\n","1.   The [SavedModel format](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format) (default).\n","2.   [The HDF5 format](https://www.tensorflow.org/tutorials/keras/save_and_load#hdf5_format)\n"],"metadata":{"id":"elek0UfIIwis"}},{"cell_type":"markdown","source":["The main difference between the two is the SavedModel is automatically able to save custom objects (such as special layers) without additional modifications when loading the model back in."],"metadata":{"id":"j0hwPPcTJO77"}},{"cell_type":"code","source":["# Save a model using the SavedModel format\n","model.save('best_model_SavedModel_format')\n","# Save a model using the HDF5 format\n","model.save(\"best_model_HDF5_format.h5\") # note the addition of '.h5' on the end"],"metadata":{"id":"HF7mZ2icIL8a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a model from the SavedModel format\n","loaded_saved_model = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n","loaded_saved_model.summary()"],"metadata":{"id":"MYUBxPmHJbWU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.7\n","Understand the compatibility discrepancies between different versions of TensorFlow\n","**TODO**"],"metadata":{"id":"vOqKDUZ8dDjW"}},{"cell_type":"markdown","source":["# Part 2: Building and training neural network models using TensorFlow 2.x\n","You need to understand the foundational principles of machine learning (ML) and deep learning (DL) using TensorFlow 2.x."],"metadata":{"id":"PBWh0V_Ffhtr"}},{"cell_type":"markdown","source":["## 2.1\n","Use TensorFlow 2.x.\n","**DONE GENERIC**\n"],"metadata":{"id":"Jrw7mG6KfxXK"}},{"cell_type":"markdown","source":["## 2.2\n","Build, compile and train machine learning (ML) models using TensorFlow.\n","**DONE**\n","\n","\n","1.   Creating a model - piece together the layers of a neural network yourself (using the [Functional](https://www.tensorflow.org/guide/keras/functional) or [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) API) \n","2.   Compiling a model - defining Loss, Metrics and Optimizer\n","3.   Fitting a model\n","\n"],"metadata":{"id":"RwTna4Z7f7w5"}},{"cell_type":"code","source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Create a model using the Sequential API\n","model = tf.keras.Sequential([\n","  tf.keras.layers.Dense(1)\n","])\n","\n","# Compile the model\n","model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n","              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n","              metrics=[\"mae\"])\n","\n","# Fit the model\n","# model.fit(X, y, epochs=5) # this will break with TensorFlow 2.7.0+\n","model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"],"metadata":{"id":"-qscyks1cAAr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3\n","Preprocess data to get it ready for use in a model.\n","**DONE BUT MAKE A DOCUMENT WITH THE DIFFERENT WAYS**"],"metadata":{"id":"es_8RFP2gBuJ"}},{"cell_type":"markdown","source":["https://www.tensorflow.org/guide/data Ti fa fare un sacco di cose fiche nell'importing di varie datasources in tf.dataframe"],"metadata":{"id":"tsJdpkH8gFcJ"}},{"cell_type":"markdown","source":["Normalization and Standardization\n","\n","\n","1.   Normalization (scaling all values from their original range to be between 0 and 1\n","2.   Standardization which converts all of your data to unit variance and 0 mean.\n","\n"],"metadata":{"id":"vly0oB11Lic7"}},{"cell_type":"markdown","source":["When you are dealing with text data you have to convert string in numbers, we will see better in NLP part"],"metadata":{"id":"TuZXx8yWMOZc"}},{"cell_type":"markdown","source":["Sometimes you have a non dummy variable so it is bettere to use hot-encoding"],"metadata":{"id":"QBxiXIHkMfKU"}},{"cell_type":"code","source":["import pandas as pd\n","# Read in the insurance dataset\n","insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n","# Turn all categories into numbers\n","insurance_one_hot = pd.get_dummies(insurance)\n","insurance_one_hot.head() # view the converted columns"],"metadata":{"id":"nfV9ZaAnMlck"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.4\n","Use models to predict results.\n"],"metadata":{"id":"6XPu1jIpgF05"}},{"cell_type":"code","source":["# Make predictions\n","y_preds = model.predict(X_test)"],"metadata":{"id":"vW601j2LGl6z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.5\n","Build sequential models with multiple layers.\n","**DONE +-**"],"metadata":{"id":"-OVLrbYygJti"}},{"cell_type":"markdown","source":["[Functional](https://www.tensorflow.org/guide/keras/functional) or [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) API"],"metadata":{"id":"hWUgnjh8uZE_"}},{"cell_type":"markdown","source":["## 2.6\n","Build and train models for binary classification.\n","**DONE +-**"],"metadata":{"id":"jdmBhkv7gNpI"}},{"cell_type":"markdown","source":["The principal solution with a binary classification is to use a sigmoid activation function in the output layer, binary cross entropy as loss function and accuracy as base metric(we have a plenty of binary classification metrics for more elaborated model comparisons)"],"metadata":{"id":"joEGp00x19rO"}},{"cell_type":"code","source":["##### BINARY CLASSIFICATION BASIC EXAMPLE\n","# Set random seed\n","tf.random.set_seed(42)\n","\n","# Create a model\n","model_7 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n","  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n","  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation #############################\n","])\n","\n","# Compile the model\n","model_7.compile(loss=tf.keras.losses.binary_crossentropy, #LOSS FUNCTION ==> BINARY CROSS ENTROPY ####################################\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=['accuracy']) #MOST USED EVALUATION METRIC ==> ACCURACY\n","\n","# Fit the model\n","history = model_7.fit(X, y, epochs=100, verbose=0)"],"metadata":{"id":"Jgx7Yj0314NV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.7\n","Build and train models for multi-class categorization.\n","**DONE +-**"],"metadata":{"id":"iS7z66lzgSqh"}},{"cell_type":"markdown","source":["It's mainly the same of binary, we have to change:\n","\n","1.   Output size: numer of classes\n","2.   Output activation function: softmax\n","3.   Loss Function: Categorical Cross Entropy(CCE)\n","        31.   Sparse CCE if the labels are expressed in integer form\n","        32.   CCE if labels are expressed in hot-encoding form\n","\n","\n","\n","\n","\n"],"metadata":{"id":"R1M19vZu_i0-"}},{"cell_type":"markdown","source":["## 2.8\n","Plot loss and accuracy of a trained model.\n","**DONE**"],"metadata":{"id":"OuwRYKixgXSY"}},{"cell_type":"markdown","source":["Faster way is to save the history, the output of .fit function of a model, and use Pandas to plot it. The content of the history will depend on the loss function we use, the metrics we set in compiling the model and optionally some callback that writes its information in history"],"metadata":{"id":"jzmtYKdnK1WS"}},{"cell_type":"code","source":["# This is a regression model, so we do not have the accuracy, for more lines in the plot we need to specify more metrics in the compiling part of the model\n","history_2 = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)\n","# Plot the model trained for 200 total epochs loss curves\n","pd.DataFrame(history_2.history).plot()\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epochs\"); # note: epochs will only show 100 since we overrid the history variable"],"metadata":{"id":"e-D_zX0HLCsj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.9\n","Identify strategies to prevent overfitting, including augmentation and dropout.\n","**DONE BUT MAKE DOCUMENT**"],"metadata":{"id":"5BDo_MWHgcMo"}},{"cell_type":"markdown","source":["Augmentation is a preventing overfitting technique used only for image recognition, it consist on randomly alter the images of train dataset in way to not make learning too dependent on train set(overfitting)"],"metadata":{"id":"_vztI1JiueKV"}},{"cell_type":"markdown","source":["In TF we can do it in two ways:\n","\n","\n","*   Using ImageDataGenerator object\n","*   Creating an ad hoc layer in the model with tf.keras.layers.experimental.preprocessing\n","\n"],"metadata":{"id":"D1u5zFXYwV74"}},{"cell_type":"code","source":["# Create ImageDataGenerator training instance with data augmentation\n","train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n","                                             rotation_range=20, # rotate the image slightly between 0 and 20 degrees (note: this is an int not a float)\n","                                             shear_range=0.2, # shear the image\n","                                             zoom_range=0.2, # zoom into the image\n","                                             width_shift_range=0.2, # shift the image width ways\n","                                             height_shift_range=0.2, # shift the image height ways\n","                                             horizontal_flip=True) # flip the image on the horizontal axis\n","\n","# Create ImageDataGenerator training instance without data augmentation\n","train_datagen = ImageDataGenerator(rescale=1/255.) \n","\n","# Create ImageDataGenerator test instance without data augmentation\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","# Import data and augment it from training directory\n","print(\"Augmented training images:\")\n","train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n","                                                                   target_size=(224, 224),\n","                                                                   batch_size=32,\n","                                                                   class_mode='binary',\n","                                                                   shuffle=False) # Don't shuffle for demonstration purposes, usually a good thing to shuffle\n","\n","# Create non-augmented data batches\n","print(\"Non-augmented training images:\")\n","train_data = train_datagen.flow_from_directory(train_dir,\n","                                               target_size=(224, 224),\n","                                               batch_size=32,\n","                                               class_mode='binary',\n","                                               shuffle=False) # Don't shuffle for demonstration purposes\n","\n","print(\"Unchanged test images:\")\n","test_data = test_datagen.flow_from_directory(test_dir,\n","                                             target_size=(224, 224),\n","                                             batch_size=32,\n","                                             class_mode='binary')"],"metadata":{"id":"ai9fU3CpwvyD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","# Create a data augmentation stage with horizontal flipping, rotations, zooms\n","data_augmentation = keras.Sequential([\n","  preprocessing.RandomFlip(\"horizontal\"),\n","  preprocessing.RandomRotation(0.2),\n","  preprocessing.RandomZoom(0.2),\n","  preprocessing.RandomHeight(0.2),\n","  preprocessing.RandomWidth(0.2),\n","  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n","], name =\"data_augmentation\")\n","\n","# and use it in a model with functional API, it should work even with sequential API\n","# Setup input shape and base model, freezing the base model layers\n","input_shape = (224, 224, 3)\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = False\n","# Create input layer\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","# Add in data augmentation Sequential model as a layer\n","x = data_augmentation(inputs)\n","# Give base_model inputs (after augmentation) and don't train it\n","x = base_model(x, training=False)\n","# Pool output features of base model\n","x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n","# Put a dense layer on as the output\n","outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n","# Make a model with inputs and outputs\n","model_1 = keras.Model(inputs, outputs)"],"metadata":{"id":"twv5QNAcx0u4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged."],"metadata":{"id":"oi1XYX436Jo_"}},{"cell_type":"code","source":["combined_dropout = layers.Dropout(0.5)(token_char_concat)"],"metadata":{"id":"33vB5rUM6Mju"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.10\n","Use pretrained models (transfer learning).\n","**DONE +-**"],"metadata":{"id":"6NEmfxsqggQh"}},{"cell_type":"markdown","source":["Tranfer learning is using a model already trained in way to not waste time in training if the model is huge, the easier way is to use the original model as it is, but we can even modify the output layer in way to adapt the pretrained model to our task(FEATURE EXTRACTION)"],"metadata":{"id":"DAFwwP3y2n2R"}},{"cell_type":"code","source":["# Resnet 50 V2 feature vector\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n","\n","# Download the pretrained model and save it as a Keras layer\n","feature_extractor_layer = hub.KerasLayer(resnet_url,\n","                                          trainable=False, # freeze the underlying patterns\n","                                          name='feature_extraction_layer',\n","                                          input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n","\n","# Create our own model\n","resnet_model = tf.keras.Sequential([\n","  feature_extractor_layer, # use the feature extraction layer as the base\n","  layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer      \n","])\n","\n","# Compile\n","resnet_model.compile(loss='categorical_crossentropy',\n","                     optimizer=tf.keras.optimizers.Adam(),\n","                     metrics=['accuracy'])\n","# Fit the model\n","resnet_history = resnet_model.fit(train_data_10_percent,\n","                                  epochs=5,\n","                                  steps_per_epoch=len(train_data_10_percent),\n","                                  validation_data=test_data,\n","                                  validation_steps=len(test_data),\n","                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n","                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", # save experiment logs here\n","                                                                         experiment_name=\"resnet50V2\")]) # name of log files\n"],"metadata":{"id":"xR-QOWYq3jAx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.11\n","Extract features from pre-trained models.\n","**DONE +-**"],"metadata":{"id":"Wl6XUUsUgk2n"}},{"cell_type":"markdown","source":["Fine tuning is a more complex way, it consist to get a pretrained model, maybe adjusting the output layer, and train again the last layers (not only the output layer), it takes more time but can archieve better performance."],"metadata":{"id":"e3x4WRCl4nQD"}},{"cell_type":"markdown","source":["In the code below we will train a model with feature extraction for 5 epochs and then we will unfreeze the last layers and train the modeel for 5 epochs more "],"metadata":{"id":"mmrEK51Q5oY-"}},{"cell_type":"code","source":["## FEATURE EXTRACTION\n","# Create a functional model with data augmentation\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","from tensorflow.keras.models import Sequential\n","\n","# Build data augmentation layer\n","data_augmentation = Sequential([\n","  preprocessing.RandomFlip('horizontal'),\n","  preprocessing.RandomHeight(0.2),\n","  preprocessing.RandomWidth(0.2),\n","  preprocessing.RandomZoom(0.2),\n","  preprocessing.RandomRotation(0.2),\n","  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNet                 \n","], name=\"data_augmentation\")\n","\n","# Setup the input shape to our model\n","input_shape = (224, 224, 3)\n","\n","# Create a frozen base model\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = False\n","\n","# Create input and output layers\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\") # create input layer\n","x = data_augmentation(inputs) # augment our training images\n","x = base_model(x, training=False) # pass augmented images to base model but keep it in inference mode, so batchnorm layers don't get updated: https://keras.io/guides/transfer_learning/#build-a-model \n","x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n","outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n","model_2 = tf.keras.Model(inputs, outputs)\n","\n","# Compile\n","model_2.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(lr=0.001), # use Adam optimizer with base learning rate\n","              metrics=[\"accuracy\"])\n","\n","# Fit the model saving checkpoints every epoch\n","initial_epochs = 5\n","history_10_percent_data_aug = model_2.fit(train_data_10_percent,\n","                                          epochs=initial_epochs,\n","                                          validation_data=test_data,\n","                                          validation_steps=int(0.25 * len(test_data)), # do less steps per validation (quicker)\n","                                          callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_data_aug\")])\n","\n","# FINE TUNING\n","base_model.trainable = True\n","\n","# Freeze all layers except for the\n","for layer in base_model.layers[:-10]:\n","  layer.trainable = False\n","\n","# Recompile the model (always recompile after any adjustments to a model)\n","model_2.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr is 10x lower than before for fine-tuning\n","              metrics=[\"accuracy\"])\n","\n","# Fine tune for another 5 epochs\n","fine_tune_epochs = initial_epochs + 5\n","\n","# Refit the model (same as model_2 except with more trainable layers)\n","history_fine_10_percent_data_aug = model_2.fit(train_data_10_percent,\n","                                               epochs=fine_tune_epochs,\n","                                               validation_data=test_data,\n","                                               initial_epoch=history_10_percent_data_aug.epoch[-1], # start from previous last epoch\n","                                               validation_steps=int(0.25 * len(test_data)),\n","                                               callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_fine_tune_last_10\")]) # name experime"],"metadata":{"id":"sOt5rq8n5mX7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.12\n","Ensure that inputs to a model are in the correct shape.\n","**DONE +-**"],"metadata":{"id":"rJtCDz3qgo1w"}},{"cell_type":"markdown","source":["## 2.13\n","Ensure that you can match test data to the input shape of a neural network.\n","**DONE BUT MAKE DOCUMENT**"],"metadata":{"id":"Cdd59BzThh_u"}},{"cell_type":"markdown","source":["## 2.14\n","Ensure you can match output data of a neural network to specified input shape for test data.\n","**DONE +-**"],"metadata":{"id":"3AuHWS75hmAG"}},{"cell_type":"markdown","source":["## 2.15\n","Understand batch loading of data.\n","**DONE +-**"],"metadata":{"id":"W471eEXxhpel"}},{"cell_type":"markdown","source":["## 2.16\n","Use callbacks to trigger the end of training cycles.\n","**DONE BUT MAKE DOCUMENT**"],"metadata":{"id":"08_4ely7htDf"}},{"cell_type":"markdown","source":["Callbacks are functions operating inside the training of NN, this functions have a purpose and give an output at the end of every epoch, in this way you can save information at every epochs and make actions based on this info(early stopping, learning rate adaptation)"],"metadata":{"id":"Ak44X3vc-I0d"}},{"cell_type":"markdown","source":["Kind of callbacks we saw:\n","1.   TensorBoard callback: saves model metrics in a log_dir in way that you can acces them using TensorBoard\n","2.   Model ChackPoint callback: saves the model every epoch, or every performance increasing epoch\n","3.   Early Stopping callback\n","4.   Learning Rate Adaptation\n","\n","\n","\n"],"metadata":{"id":"xrG2Hzw7_Ud7"}},{"cell_type":"code","source":["##TENSORBOARD CALLBACK\n","# Create tensorboard callback (functionized because need to create a new one for each model)\n","import datetime\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=log_dir\n","  )\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback\n","\n","# Use it in training\n","# Fit the model\n","resnet_history = resnet_model.fit(train_data_10_percent,\n","                                  epochs=5,\n","                                  steps_per_epoch=len(train_data_10_percent),\n","                                  validation_data=test_data,\n","                                  validation_steps=len(test_data),\n","                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n","                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", # save experiment logs here\n","                                                                         experiment_name=\"resnet50V2\")]) # name of log files\n","\n","## MODEL CHACKPOINT CALLBACK\n","# Setup checkpoint path\n","checkpoint_path = \"ten_percent_model_checkpoints_weights/checkpoint.ckpt\" # note: remember saving directly to Colab is temporary\n","\n","# Create a ModelCheckpoint callback that saves the model's weights only\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                         save_weights_only=True, # set to False to save the entire model\n","                                                         save_best_only=False, # set to True to save only the best model instead of a model every epoch \n","                                                         save_freq=\"epoch\", # save every epoch\n","                                                         verbose=1)\n","## EARLY STOPPING CALLBACK\n","# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n","                                                  patience=3) # if val loss decreases for 3 epochs in a row, stop training\n","\n","## LEARNING RATE ADAPTATION CALLBACK\n","# Creating learning rate reduction callback\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n","                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n","                                                 patience=2,\n","                                                 verbose=1, # print out when learning rate goes down \n","                                                 min_lr=1e-7)\n"],"metadata":{"id":"NJB1Hp3TFwjG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.17\n","Use datasets from different sources.\n","**DONE BUT MAKE DOCUMENT**\n"],"metadata":{"id":"KeEEGh0khwtV"}},{"cell_type":"markdown","source":["tf.dataset are useful because can be managed by GPU, this increases the performance of training, that's the reason why tf.keras.prepreprocessing.image_dataset_from_directory() outperform ImageDataGenerator **TODO**"],"metadata":{"id":"jDI3wVfnIMog"}},{"cell_type":"markdown","source":["## 2.18\n","Use datasets in different formats, including json and csv.\n","**DONE +-**"],"metadata":{"id":"BoC_QJvoh0EX"}},{"cell_type":"markdown","source":["## 2.19\n","Use datasets from tf.data.datasets.\n","**TODO**"],"metadata":{"id":"RDAWkGjVh4SX"}},{"cell_type":"markdown","source":["tf.dataset are faster in preprocessing because the function operating on them are computated by GPU and is possible to apply mixed precision training, but are a bit more complex to manage:\n","\n","\n","1.   Have to be scaled and resized with functions\n","2.   Have to be batched and prepared for training\n","\n"],"metadata":{"id":"HoXAN2mLhpI9"}},{"cell_type":"markdown","source":["tf.dataset data preprocessing\n","\n","\n","1.   Cast data in tensors\n","2.   Image resizing to a standard size\n","3.   Scaling values in tensors\n","\n","For semplicity you can create a function doing this trasformation and apply to tf.dataset using **.map()** function\n","\n","\n","\n"],"metadata":{"id":"_0PJi0C4lIMC"}},{"cell_type":"code","source":["# Cast data\n","tf.cast(image, tf.float32)\n","# Image resizing\n","img_shape = 224\n","tf.image.resize(image, [img_shape, img_shape])\n","#scaling values\n","image = image/255"],"metadata":{"id":"wsFR-NY8lpA9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["tf.dataset DATA PREPARATION AND BATCHING\n","1.  Appling all the data preprocessing trasformation using map()\n","2.  Sufffle the element in dataset unsing **.shuffle()** function with **buffer_size** as parameter, the buffer should theorically be the entire dataset, but for memory reasons we have to do it in batches, i.e. the **buffer_size**\n","3.  Batching the data to make the training sustainable\n","4.  Prefetch the data in way to parallelize computation between CPU(preprocessing and preparation) and GPU(actual training of the model)\n","5.  Cache the data in a target dataset in way to avoid loading time, but for now we do not use it \n"],"metadata":{"id":"-ZObwe2TmJk1"}},{"cell_type":"code","source":["# Map preprocessing function to training data (and paralellize)\n","train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n","# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n","train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n","\n","# Map prepreprocessing function to test data\n","test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n","# Turn test data into batches (don't need to shuffle)\n","test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"5X_5SK8Xp6xO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.20\n","Split data in train and test set"],"metadata":{"id":"CviyTAHAFApF"}},{"cell_type":"markdown","source":["Easy and naive way is to define a splitting proportion and index the array to divide test and train, remember that is not a random split"],"metadata":{"id":"34u2k8hrFNLN"}},{"cell_type":"code","source":["import numpy as np\n","# Make a bigger dataset\n","X = np.arange(-100, 100, 4)\n","# Make labels for the dataset (adhering to the same pattern as before)\n","y = np.arange(-90, 110, 4)\n","print(f\"Len of data: {len(X)}\")\n","# Split data into train and test sets\n","X_train = X[:40] # first 40 examples (80% of data)\n","y_train = y[:40]\n","\n","X_test = X[40:] # last 10 examples (20% of data)\n","y_test = y[40:]\n","\n","len(X_train), len(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0zQZ7BpF2Ut","executionInfo":{"status":"ok","timestamp":1646752502565,"user_tz":-60,"elapsed":263,"user":{"displayName":"tiziano medas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12272265020738565914"}},"outputId":"ab0a7031-f013-4248-917b-3635b755f82e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Len of data: 50\n"]},{"output_type":"execute_result","data":{"text/plain":["(40, 10)"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Using sklearn.train_test_split to split randomly the data "],"metadata":{"id":"0ngTppTpKUIL"}},{"cell_type":"code","source":["# Create training and test sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, \n","                                                    y, \n","                                                    test_size=0.2, \n","                                                    random_state=42) # set random state for reproducible splits"],"metadata":{"id":"LECqz9qSKU07"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2.21\n","Enable mixed precision training and check it"],"metadata":{"id":"5Gcb05reqKZj"}},{"cell_type":"markdown","source":["Mixed precisiono trainig use float16, instead of float32, so we can speed up the trainig time losing a bit of precision in computation"],"metadata":{"id":"uMi960GpqVKW"}},{"cell_type":"code","source":["# Turn on mixed precision training\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision\n","mixed_precision.global_policy() # should output \"mixed_float16\""],"metadata":{"id":"GvzNomMBqn9X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 3: Image classification\n","You need to understand how to build image recognition and object detection models with deep neural\n","networks and convolutional neural networks using TensorFlow 2.x."],"metadata":{"id":"NnZGbk8ZW3Bs"}},{"cell_type":"markdown","source":["##3.1\n","Define Convolutional neural networks with Conv2D and pooling layers."],"metadata":{"id":"8RjMGF9OXEK4"}},{"cell_type":"markdown","source":["Conv2D takes the following input shapes, at least 3 rank matrix\n","\n","*   4+D tensor with shape: batch_shape + (channels, rows, cols) if \n","data_format='channels_first' or 4+D tensor with shape: batch_shape + (rows, cols, channels) if data_format='channels_last'.\n","\n","MaxPool2D takes an input shape of 2 rank matrix"],"metadata":{"id":"zYw0dYtDkZVE"}},{"cell_type":"code","source":["#Example of model with Conv2D and MaxPool2D\n","# Create the model (this can be our baseline, a 3 layer Convolutional Neural Network)\n","model_4 = Sequential([\n","  Conv2D( # The \"2D\" means our inputs are two dimensional (height and width), even though they have 3 colour channels, the convolutions are run on each channel invididually.\n","         filters=10, # these are the number of \"feature extractors\" that will be moving over our images.\n","         kernel_size=3, # the size of our filters, a kernel_size of (3, 3) will mean each filter will have the size 3x3. The smaller the kernel, the more fine-grained features it will extract.\n","         strides=1, # the number of pixels a filter will move across as it covers the image. A stride of 1 means the filter moves across each pixel 1 by 1.\n","         padding='valid', # this can be either 'same' or 'valid', 'same' adds zeros the to outside of the image so the resulting output of the convolutional layer is the same as the input,\n","         activation='relu', \n","         input_shape=(224, 224, 3)), # input layer (specify input shape)\n","  Conv2D(10, 3, activation='relu'),\n","  Conv2D(10, 3, activation='relu'),\n","  Flatten(),\n","  Dense(1, activation='sigmoid') # output layer (specify output shape)\n","])\n","# Compile the model\n","model_4.compile(loss='binary_crossentropy',\n","                optimizer=Adam(),\n","                metrics=['accuracy'])"],"metadata":{"id":"xXpyMuSjimRQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check lengths of training and test data generators\n","len(train_data), len(test_data)\n","\n","# Fit the model\n","history_4 = model_4.fit(train_data,\n","                        epochs=5,\n","                        steps_per_epoch=len(train_data), #this is the number of batches a model will go through per epoch,\n","                        #in our case, we want our model to go through all batches so it's equal to the length of train_data (1500 images in batches of 32 = 1500/32 = ~47 steps)\n","                        validation_data=test_data,\n","                        validation_steps=len(test_data)) #same as above, except for the validation_data parameter"],"metadata":{"id":"gWoYJnNi5z_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For multi-class classification we had to make 3 main changes:\n","\n","\n","1.   Changing the output layer to use have n ouput neurons (the same number as the number of classes we have).\n","2.   Changing the output layer to use 'softmax' activation instead of 'sigmoid' activation.\n","3.   Changing the loss function to be 'categorical_crossentropy' instead of 'binary_crossentropy'.\n","\n","\n"],"metadata":{"id":"H5bimmaTPYjt"}},{"cell_type":"markdown","source":["## 3.2\n","Build and train models to process real-world image datasets.\n"],"metadata":{"id":"zhm6KCl3YgKt"}},{"cell_type":"markdown","source":["We need to reshape the real world images, usual size is (224, 224, 3),"],"metadata":{"id":"2LcpjbEawRkw"}},{"cell_type":"markdown","source":["##3.3\n","Understand how to use convolutions to improve your neural network.\n"],"metadata":{"id":"Tos2FmYYYkWu"}},{"cell_type":"markdown","source":["\n","Some tips to improve the image classification model are:\n","*   Increase the number of model layers (e.g. add more convolutional layers).\n","*   Increase the number of filters in each convolutional layer (e.g. from 10 to 32, 64, or 128, these numbers aren't set in stone either, they are usually found through trial and error).\n","*   Train for longer (more epochs).\n","*   Finding an ideal learning rate.\n","*   Get more data (give the model more opportunities to learn).\n","*   Use transfer learning to leverage what another image model has learned and adjust it for our own use case.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"WELyIjS-KgTt"}},{"cell_type":"markdown","source":["##3.4\n","Use real-world images in different shapes and sizes."],"metadata":{"id":"Wx_kmKzBYoNg"}},{"cell_type":"markdown","source":["\n","\n","*   See point 3.6, the parameter target_size in train_datagen.flow_from_directory reshapes the image \n","*   We can also use tf.io.read_file and tf.image, the example code is below "],"metadata":{"id":"sjblS1PrEk7e"}},{"cell_type":"code","source":["# Read in target file (an image)\n","img = tf.io.read_file(filename)\n","\n","# Decode the read file into a tensor & ensure 3 colour channels \n","# (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n","img = tf.image.decode_image(img, channels=3)\n","\n","# Resize the image (to the same size our model was trained on)\n","img = tf.image.resize(img, size = [img_shape, img_shape])\n","\n","# Rescale the image (get all values between 0 and 1)\n","img = img/255.\n","\n","#Thaìn you have to manage the batch size dimension, by adding a dimension to the image tensor\n","img = tf.expand_dims(img, axis=0) # add an extra dimension at axis 0"],"metadata":{"id":"et8mn7VlMNUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##3.5\n","Use image augmentation to prevent overfitting."],"metadata":{"id":"b8KUws9aYrVF"}},{"cell_type":"markdown","source":["We can increase the number of layers with pooling, bot MaxPool and AvgPool ==> We have seen how to do it in the build part of the model "],"metadata":{"id":"RSZjQKq7GNTJ"}},{"cell_type":"markdown","source":["We can use data augmentation, which is the process of altering our training data, leading to it having more diversity and in turn allowing our models to learn more generalizable patterns."],"metadata":{"id":"7r7ZvGp6GnhI"}},{"cell_type":"code","source":["#We can do it directly with the ImageDataGenerator Object initialization\n","# Create ImageDataGenerator training instance with data augmentation\n","train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n","                                             rotation_range=20, # rotate the image slightly between 0 and 20 degrees (note: this is an int not a float)\n","                                             shear_range=0.2, # shear the image\n","                                             zoom_range=0.2, # zoom into the image\n","                                             width_shift_range=0.2, # shift the image width ways\n","                                             height_shift_range=0.2, # shift the image height ways\n","                                             horizontal_flip=True) # flip the image on the horizontal axis\n","\n","# Create ImageDataGenerator training instance without data augmentation\n","train_datagen = ImageDataGenerator(rescale=1/255.) \n","\n","# Create ImageDataGenerator test instance without data augmentation\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","# Import data and augment it from directories\n","train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n","                                                                            target_size=(224, 224),\n","                                                                            batch_size=32,\n","                                                                            class_mode='binary',\n","                                                                            shuffle=True) # Shuffle data (default) Means that shuffles the data between the labels in each batch\n","                                                                            # if its false it passes to batch at firts all the images from a directory and the the other one"],"metadata":{"id":"bZ_ONRctHGyJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Other ways to prevent overfitting, preventing overfitting is also referred to as regularization:\n","\n","\n","1.   Get more data - Having more data gives the model more opportunities to learn patterns, patterns which may be more generalizable to new examples.\n","2.   Simplify model - If the current model is already overfitting the training data, it may be too complicated of a model. This means it's learning the patterns of the data too well and isn't able to generalize well to unseen data. One way to simplify a model is to reduce the number of layers it uses or to reduce the number of hidden units in each layer.\n","3.   Use data augmentation - Data augmentation manipulates the training data in a way so that's harder for the model to learn as it artificially adds more variety to the data. If a model is able to learn patterns in augmented data, the model may be able to generalize better to unseen data.\n","4.   Use transfer learning - Transfer learning involves leverages the patterns (also called pretrained weights) one model has learned to use as the foundation for your own task. In our case, we could use one computer vision model pretrained on a large variety of images and then tweak it slightly to be more specialized for food images.\n","\n","\n","\n"],"metadata":{"id":"fbT49J-h2h1Q"}},{"cell_type":"markdown","source":["##3.6\n","Use ImageDataGenerator.\n"],"metadata":{"id":"Y_gABadcYuVP"}},{"cell_type":"markdown","source":["ImageDataGeneratir is a usefull tool when you have images splitted into directories, it enables you to rescale and resize the images, augmented them and also creates a stream of batches from the train and test directories which flows directly inside the training neural network"],"metadata":{"id":"QxcV7njeyKVD"}},{"cell_type":"code","source":["# Create train and test data generators and rescale the data \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","# Turn it into batches\n","train_data = train_datagen.flow_from_directory(directory=train_dir, # define the directory of train data, note that it has 2 subdir for the 2 classes, the model takes the labels from subdir names\n","                                               target_size=(224, 224), # define the target size in which we will reshape \n","                                               class_mode='binary', # define the classification type, if classes are > 2 we have to write 'categorical'\n","                                               batch_size=32) #define batch size\n","\n","test_data = test_datagen.flow_from_directory(directory=test_dir,\n","                                             target_size=(224, 224),\n","                                             class_mode='binary',\n","                                             batch_size=32)"],"metadata":{"id":"An-TJ2qjyK1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a sample of the training data batch \n","images, labels = train_data.next() # get the 'next' batch of images/labels\n","len(images), len(labels)"],"metadata":{"id":"dgT9mB_p0jZV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##3.7\n","Understand how ImageDataGenerator labels images based on the directory structure."],"metadata":{"id":"XCkTYmx5Y1nv"}},{"cell_type":"markdown","source":["# Part 4: NLP\n","You need to understand how to use neural networks to solve natural language processing problems\n","using TensorFlow."],"metadata":{"id":"N4BUJxZzHmlm"}},{"cell_type":"markdown","source":["##4.1\n","Build natural language processing systems using TensorFlow.\n"],"metadata":{"id":"oqW1gFTBHz4d"}},{"cell_type":"markdown","source":["##4.2\n","Prepare text to use in TensorFlow models. TOKENIZATION\n"],"metadata":{"id":"Yu_Ud2KkIFNa"}},{"cell_type":"markdown","source":[" A straight mapping from word or character or sub-word to a numerical value, there are 3 levels:\n"," 1.  Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n"," 2.  Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n"," 3.  Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens."],"metadata":{"id":"PffMMjkQotab"}},{"cell_type":"markdown","source":["tf.keras.layers.experimental.preprocessing.TextVectorization **DOCUMENTATION**\n","1.  max_tokens - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n","2.  standardize - Method for standardizing text. Default is \"lower_and_strip_punctuation\" which lowers text and removes all punctuation marks.\n","3.  split - How to split text, default is \"whitespace\" which splits on spaces.\n","4.  ngrams - How many words to contain per token split, for example, ngrams=2 splits tokens into continuous sequences of 2.\n","5.  output_mode - How to output tokens, can be \"int\" (integer mapping), \"binary\" (one-hot encoding), \"count\" or \"tf-idf\". See documentation for more.\n","6.  output_sequence_length - Length of tokenized sequence to output. For example, if output_sequence_length=150, all tokenized sequences will be 150 tokens long.\n","7.  pad_to_max_tokens - Defaults to False, if True, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens. Only valid in certain modes, see docs for more."],"metadata":{"id":"bpKDEeB_hOEn"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","# Setup text vectorization with custom variables\n","max_vocab_length = 10000 # max number of words to have in our vocabulary\n","max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n","\n","text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n","                                    output_mode=\"int\",\n","                                    output_sequence_length=max_length)\n","# Fit the text vectorizer to the training text\n","text_vectorizer.adapt(train_sentences)\n","# Create sample sentence and tokenize it\n","sample_sentence = \"There's a flood in my street!\"\n","text_vectorizer([sample_sentence])"],"metadata":{"id":"tJaZY-g2iDcG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4.3\n","Build models that identify the category of a piece of text using binary categorization\n"],"metadata":{"id":"aAJaVV3WIINF"}},{"cell_type":"code","source":["# Example of basic dense model for binary categorization, it's very bad in performances \n","# Build model with the Functional API\n","from tensorflow.keras import layers\n","inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n","x = text_vectorizer(inputs) # turn the input text into numbers\n","x = embedding(x) # create an embedding of the numerized numbers\n","x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n","model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n","\n","# Compile model\n","model_1.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n","# Fit the model\n","model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n","                                                                     experiment_name=\"simple_dense_model\")])"],"metadata":{"id":"0fPQC1nPj2Qa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4.4\n","Build models that identify the category of a piece of text using multi-class categorization\n"],"metadata":{"id":"d0b2v9eaIKyl"}},{"cell_type":"markdown","source":["Basically the difference between multinomial and binary categorization remain the same, such as the loss function, the numbers of neurons and activation function of the output layer, but in this poin we will explore the structure of complex multi-class models in way to understand how to build them.\n","\n","A complex model can be structured as concatenation of simple models and the Functional API gives use a powerful tool to implement them, some focal points:\n","1.  Contruct the simple model part\n","2.  Concatenate the simple model output, using concatenation layers, i.e. layers of the final NN with the only purpose to concatenate matrix in way to have a tensor of inputs for the complex layers of our NN\n","3.  Define the complessive model using the output layer as the result of the overall functional transformations of the previous layers and the model inputs as the concatenation of the very first layers of the different parts of NN \n","4.  The last part is to generate a tf.dataset matching with the inputs of the overall model and then zip the labels, the best way is to using **tf.data.Dataset.from_tensor_slices**, you can think **tf.data.Dataset.from_tensor_slices** as a structure which contains different tensors(different datatype and tensors sizes are possible) in way to have all the needed features for the training, do not think about a linear algebra concatenatrion is something more flexible. "],"metadata":{"id":"Rz3FDF8hoY-g"}},{"cell_type":"code","source":["# DEFINITION OF THE COMPLEX MODEL\n","# 1. Token inputs\n","token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n","token_embeddings = tf_hub_embedding_layer(token_inputs)\n","token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n","token_model = tf.keras.Model(inputs=token_inputs,\n","                             outputs=token_outputs)\n","\n","# 2. Char inputs\n","char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n","char_vectors = char_vectorizer(char_inputs)\n","char_embeddings = char_embed(char_vectors)\n","char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n","char_model = tf.keras.Model(inputs=char_inputs,\n","                            outputs=char_bi_lstm)\n","\n","# 3. Line numbers inputs\n","line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n","x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n","line_number_model = tf.keras.Model(inputs=line_number_inputs,\n","                                   outputs=x)\n","\n","# 4. Total lines inputs\n","total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n","y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n","total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n","                                  outputs=y)\n","\n","# 5. Combine token and char embeddings into a hybrid embedding\n","combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n","                                                                              char_model.output])\n","z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n","z = layers.Dropout(0.5)(z)\n","\n","# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n","z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n","                                                                total_line_model.output,\n","                                                                z])\n","\n","# 7. Create output layer\n","output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n","\n","# 8. Put together model\n","model_5 = tf.keras.Model(inputs=[line_number_model.input,\n","                                 total_line_model.input,\n","                                 token_model.input, \n","                                 char_model.input],\n","                         outputs=output_layer)"],"metadata":{"id":"4BQBjdUXziy_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## DEFINITION OF TRAIN AND TEST DATASET\n","# Create training and validation datasets (all four kinds of inputs)\n","train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n","                                                                train_total_lines_one_hot, # total lines\n","                                                                train_sentences, # train tokens\n","                                                                train_chars)) # train chars\n","train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n","train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n","train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n","\n","# Validation dataset\n","val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n","                                                              val_total_lines_one_hot,\n","                                                              val_sentences,\n","                                                              val_chars))\n","val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n","val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n","val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n","\n","# Check input shapes\n","train_pos_char_token_dataset, val_pos_char_token_dataset"],"metadata":{"id":"fJovLJZ0zwDF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4.5\n","Use word embeddings in your TensorFlow model.\n"],"metadata":{"id":"yBRzeVW3INwW"}},{"cell_type":"markdown","source":["An embedding is a representation of natural language which can be learned. It is a semantic, between strings and their relation are expressed in distances in the vector space. \n","1.  **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n","2.  **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."],"metadata":{"id":"AmrrzUAiVVzg"}},{"cell_type":"markdown","source":["tf.keras.layers.Embedding **DOCUMENTATION**\n","1.  input_dim - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n","2.  output_dim - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n","3.  embeddings_initializer - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n","4.  input_length - Length of sequences being passed to embedding layer."],"metadata":{"id":"NZmi2BT9iwEo"}},{"cell_type":"code","source":["tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","\n","embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n","                             output_dim=128, # set size of embedding vector\n","                             embeddings_initializer=\"uniform\", # default, intialize randomly\n","                             input_length=max_length, # how long is each input\n","                             name=\"embedding_1\") \n","\n","embedding\n","# Get a random sentence from training set\n","random_sentence = random.choice(train_sentences)\n","print(f\"Original text:\\n{random_sentence}\\\n","      \\n\\nEmbedded version:\")\n","\n","# Embed the random sentence (turn it into numerical representation)\n","sample_embed = embedding(text_vectorizer([random_sentence]))\n","sample_embed"],"metadata":{"id":"A079wEmtjc8y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4.6\n","Use LSTMs in your model to classify text for either binary or multi-class categorization.\n"],"metadata":{"id":"iRHPoY7fIQNe"}},{"cell_type":"markdown","source":["How LSTM theorically works is well known, what we say here is that in Keras you have only to be careful of the input of the LSTM layer, in the case above the ambedding layer output have shape (None, 15, 128), Keras LSTM have always, at least, 3 dim whom first is batch size. And LSTM output is (None, 64)"],"metadata":{"id":"HhGlWtNJkhtz"}},{"cell_type":"code","source":["# LSTM exmaple in binary categorization, with multi-class is the same\n","# Set random seed and create embedding layer (new embedding layer for each model)\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_2\")\n","\n","\n","# Create LSTM model\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_2_embedding(x)\n","print(x.shape)\n","# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n","x = layers.LSTM(64)(x) # return vector for whole sequence\n","print(x.shape)\n","# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n","\n","# Compile model\n","model_2.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n","\n","# Fit model\n","model_2_history = model_2.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n","                                                                     \"LSTM\")])"],"metadata":{"id":"sfPcfte3kiQM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.7\n","Add RNN and GRU layers to your model.\n"],"metadata":{"id":"pWhkfp97ISsv"}},{"cell_type":"code","source":["# Using GRU layer, compile and fit steps are the same\n","# Set random seed and create embedding layer (new embedding layer for each model)\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_3\")\n","\n","# Build an RNN using the GRU cell\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_3_embedding(x)\n","# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n","x = layers.GRU(64)(x) \n","# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"],"metadata":{"id":"_SA-HWnTnH_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using Bi-Directional LSTM layer, compile and fit steps are the same\n","# Set random seed and create embedding layer (new embedding layer for each model)\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_4\")\n","\n","# Build a Bidirectional RNN in TensorFlow\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_4_embedding(x)\n","# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n","x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"],"metadata":{"id":"t9iuI4pen8ep"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4.8\n","Use RNNS, LSTMs, GRUs and CNNs in models that work with text."],"metadata":{"id":"M3b0wWTiIWFW"}},{"cell_type":"markdown","source":["We talk about RNN and LSTM(which is a RNN) in the previous subsections, so let's focus on the use of CNN in case of text.\n","\n","The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n","\n","So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution."],"metadata":{"id":"1_TOwqUuotFa"}},{"cell_type":"code","source":["# Using Conv1D layer + MaxPool, compile and fit steps are the same\n","# Set random seed and create embedding layer (new embedding layer for each model)\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_5\")\n","\n","# Create 1-dimensional convolutional layer to model sequences\n","from tensorflow.keras import layers\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_5_embedding(x)\n","x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n","x = layers.GlobalMaxPool1D()(x)\n","# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")"],"metadata":{"id":"UZqwgg6fpm3s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4.9\n","Train LSTMs on existing text to generate text (such as songs and poetry)"],"metadata":{"id":"0lG9I4aGIZU9"}},{"cell_type":"markdown","source":["# Part 5: Time series, sequences and predictions\n","You need to understand how to solve time series and forecasting problems in TensorFlow."],"metadata":{"id":"h-ofwzL8Pedp"}},{"cell_type":"markdown","source":["##5.1\n","Train, tune and use time series, sequence and prediction models.\n"],"metadata":{"id":"d2uPRbZUPksx"}},{"cell_type":"markdown","source":["##5.2\n","Train models to predict values for both univariate and multivariate time series.\n"],"metadata":{"id":"eputBbw9Pvxo"}},{"cell_type":"markdown","source":["We saw the univariate omodel in other points, now we focus  on multivariate and even on the data preprocessing using pandas"],"metadata":{"id":"Gt67ufl-1BpX"}},{"cell_type":"code","source":["# Block reward values\n","block_reward_1 = 50 # 3 January 2009 (2009-01-03) - this block reward isn't in our dataset (it starts from 01 October 2013)\n","block_reward_2 = 25 # 28 November 2012 \n","block_reward_3 = 12.5 # 9 July 2016\n","block_reward_4 = 6.25 # 11 May 2020\n","\n","# Block reward dates (datetime form of the above date stamps)\n","block_reward_2_datetime = np.datetime64(\"2012-11-28\")\n","block_reward_3_datetime = np.datetime64(\"2016-07-09\")\n","block_reward_4_datetime = np.datetime64(\"2020-05-11\")\n","# Get date indexes for when to add in different block dates\n","block_reward_2_days = (block_reward_3_datetime - bitcoin_prices.index[0]).days\n","block_reward_3_days = (block_reward_4_datetime - bitcoin_prices.index[0]).days\n","block_reward_2_days, block_reward_3_days\n","# Add block_reward column\n","bitcoin_prices_block = bitcoin_prices.copy()\n","bitcoin_prices_block[\"block_reward\"] = None\n","\n","# Set values of block_reward column (it's the last column hence -1 indexing on iloc)\n","bitcoin_prices_block.iloc[:block_reward_2_days, -1] = block_reward_2\n","bitcoin_prices_block.iloc[block_reward_2_days:block_reward_3_days, -1] = block_reward_3\n","bitcoin_prices_block.iloc[block_reward_3_days:, -1] = block_reward_4\n","bitcoin_prices_block.head()\n","# Setup dataset hyperparameters\n","HORIZON = 1\n","WINDOW_SIZE = 7\n","# Make a copy of the Bitcoin historical data with block reward feature\n","bitcoin_prices_windowed = bitcoin_prices_block.copy()\n","\n","# Add windowed columns\n","for i in range(WINDOW_SIZE): # Shift values for each step in WINDOW_SIZE\n","  bitcoin_prices_windowed[f\"Price+{i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n","bitcoin_prices_windowed.head(10)\n","\n","# Let's create X & y, remove the NaN's and convert to float32 to prevent TensorFlow errors \n","X = bitcoin_prices_windowed.dropna().drop(\"Price\", axis=1).astype(np.float32) \n","y = bitcoin_prices_windowed.dropna()[\"Price\"].astype(np.float32)\n","X.head()\n","\n","# Make train and test sets\n","split_size = int(len(X) * 0.8)\n","X_train, y_train = X[:split_size], y[:split_size]\n","X_test, y_test = X[split_size:], y[split_size:]\n","len(X_train), len(y_train), len(X_test), len(y_test)"],"metadata":{"id":"aVcSU6g11OY3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.random.set_seed(42)\n","\n","# Make multivariate time series model\n","model_6 = tf.keras.Sequential([\n","  layers.Dense(128, activation=\"relu\"),\n","  # layers.Dense(128, activation=\"relu\"), # adding an extra layer here should lead to beating the naive model\n","  layers.Dense(HORIZON)\n","], name=\"model_6_dense_multivariate\")\n","\n","# Compile\n","model_6.compile(loss=\"mae\",\n","                optimizer=tf.keras.optimizers.Adam())\n","\n","# Fit\n","model_6.fit(X_train, y_train,\n","            epochs=100,\n","            batch_size=128,\n","            verbose=0, # only print 1 line per epoch\n","            validation_data=(X_test, y_test),\n","            callbacks=[create_model_checkpoint(model_name=model_6.name)])"],"metadata":{"id":"1YPxShIV2Yy3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##5.3\n","Prepare data for time series learning."],"metadata":{"id":"hca_dvgrPyg4"}},{"cell_type":"markdown","source":["Before to split and windowing we have to import data and generate proper tensors(they are usually pd.dataframe, np.arrays or even list), this is quite simple because we often find csv data and python as a plenty of tools which can manage csv data, pd.read_csv"],"metadata":{"id":"aUFJtbLiWycx"}},{"cell_type":"markdown","source":["Before to split we can use windowing to make our dataset splitted into labels and features in way to have a dataset for training.\n","\n","We need something like this\n","\n","[0, 1, 2, 3, 4, 5, 6] -> [7]\n","\n","[1, 2, 3, 4, 5, 6, 7] -> [8]\n","\n","[2, 3, 4, 5, 6, 7, 8] -> [9]"],"metadata":{"id":"0Z0Nn2GqZS63"}},{"cell_type":"code","source":["# Create function to label windowed data\n","def get_labelled_windows(x, horizon=1):\n","  \"\"\"\n","  Creates labels for windowed dataset.\n","\n","  E.g. if horizon=1 (default)\n","  Input: [1, 2, 3, 4, 5, 6] -> Output: ([1, 2, 3, 4, 5], [6])\n","  \"\"\"\n","  return x[:, :-horizon], x[:, -horizon:]\n","\n","# Create function to view NumPy arrays as windows \n","def make_windows(x, window_size=7, horizon=1):\n","  \"\"\"\n","  Turns a 1D array into a 2D array of sequential windows of window_size.\n","  \"\"\"\n","  # 1. Create a window of specific window_size (add the horizon on the end for later labelling)\n","  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n","  # print(f\"Window step:\\n {window_step}\")\n","\n","  # 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)\n","  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n","  # print(f\"Window indexes:\\n {window_indexes[:3], window_indexes[-3:], window_indexes.shape}\")\n","\n","  # 3. Index on the target array (time series) with 2D array of multiple window steps\n","  windowed_array = x[window_indexes]\n","\n","  # 4. Get the labelled windows\n","  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n","\n","  return windows, labels\n","\n","full_windows, full_labels = make_windows(prices, window_size=WINDOW_SIZE, horizon=HORIZON)\n","len(full_windows), len(full_labels)"],"metadata":{"id":"X__JoZnga8Pb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since in time serie order matters, it could be counter-productive to split data randomly, we will lose all the causal effects expressed by the time order, so we limit to take the first 80% of dataset as train set and the rest as test set"],"metadata":{"id":"-tKAQjOZWMqz"}},{"cell_type":"code","source":["# Make the train/test splits\n","def make_train_test_splits(windows, labels, test_split=0.2):\n","  \"\"\"\n","  Splits matching pairs of windows and labels into train and test splits.\n","  \"\"\"\n","  split_size = int(len(windows) * (1-test_split)) # this will default to 80% train/20% test\n","  train_windows = windows[:split_size]\n","  train_labels = labels[:split_size]\n","  test_windows = windows[split_size:]\n","  test_labels = labels[split_size:]\n","  return train_windows, test_windows, train_labels, test_labels\n","\n","train_windows, test_windows, train_labels, test_labels = make_train_test_splits(full_windows, full_labels)\n","len(train_windows), len(test_windows), len(train_labels), len(test_labels)"],"metadata":{"id":"eXiT8tGFWroy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##5.4\n","Understand Mean Absolute Error (MAE) and how it can be used to evaluate accuracy of\n","quence models.\n"],"metadata":{"id":"QbOcQJa4P1l4"}},{"cell_type":"markdown","source":["Here a list of most common metrics for errors in TS analysis:\n","\n","Scale-Dependent Errors\n","1.  mean absolute error\n","2.  root mean square error\n","\n","Percentage Errors\n","1.  mean absolute percentage error - to avoid if y = 0\n","2.  symmetric mean absolute percentage error\n","\n","Scaled Errors\n","1.  mean absolute scaled error"],"metadata":{"id":"B7hMLnD3YTQH"}},{"cell_type":"markdown","source":["##5.5\n","Use RNNs and CNNs for time series, sequence and forecasting models.\n"],"metadata":{"id":"PL1NX5zjP5Fv"}},{"cell_type":"markdown","source":["CNN you have to pay attention to the CNN input shape and maybe create a layer to transform input shape"],"metadata":{"id":"iWNSjOOpc384"}},{"cell_type":"code","source":["# Before we pass our data to the Conv1D layer, we have to reshape it in order to make sure it works\n","x = tf.constant(train_windows[0])\n","expand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) # add an extra dimension for timesteps\n","print(f\"Original shape: {x.shape}\") # (WINDOW_SIZE)\n","print(f\"Expanded shape: {expand_dims_layer(x).shape}\") # (WINDOW_SIZE, input_dim) \n","print(f\"Original values with expanded shape:\\n {expand_dims_layer(x)}\")\n","\n","tf.random.set_seed(42)\n","\n","# Create model\n","model_4 = tf.keras.Sequential([\n","  # Create Lambda layer to reshape inputs, without this layer, the model will error\n","  layers.Lambda(lambda x: tf.expand_dims(x, axis=1)), # resize the inputs to adjust for window size / Conv1D 3D input requirements\n","  layers.Conv1D(filters=128, kernel_size=5, padding=\"causal\", activation=\"relu\"),\n","  layers.Dense(HORIZON)\n","], name=\"model_4_conv1D\")\n","\n","# Compile model\n","model_4.compile(loss=\"mae\",\n","                optimizer=tf.keras.optimizers.Adam())\n","\n","# Fit model\n","model_4.fit(train_windows,\n","            train_labels,\n","            batch_size=128, \n","            epochs=100,\n","            verbose=0,\n","            validation_data=(test_windows, test_labels),\n","            callbacks=[create_model_checkpoint(model_name=model_4.name)])"],"metadata":{"id":"RgEO40YJcvFr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LSTM, as above pay attention to the input shape"],"metadata":{"id":"aVocXKtzdJUb"}},{"cell_type":"code","source":["tf.random.set_seed(42)\n","\n","# Let's build an LSTM model with the Functional API\n","inputs = layers.Input(shape=(WINDOW_SIZE))\n","x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n","# print(x.shape)\n","# x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n","x = layers.LSTM(128, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n","# print(x.shape)\n","# Add another optional dense layer (you could add more of these to see if they improve model performance)\n","# x = layers.Dense(32, activation=\"relu\")(x)\n","output = layers.Dense(HORIZON)(x)\n","model_5 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_5_lstm\")\n","\n","# Compile model\n","model_5.compile(loss=\"mae\",\n","                optimizer=tf.keras.optimizers.Adam())\n","\n","# Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554 \n","model_5.fit(train_windows,\n","            train_labels,\n","            epochs=100,\n","            verbose=0,\n","            batch_size=128,\n","            validation_data=(test_windows, test_labels),\n","            callbacks=[create_model_checkpoint(model_name=model_5.name)])"],"metadata":{"id":"bmJ-TEy3dN_6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##5.6\n","Identify when to use trailing versus centred windows.\n"],"metadata":{"id":"GjryomwRP7ef"}},{"cell_type":"markdown","source":["Trailing MA is the ususal one which evaluated the MA value of the windows using the n steps back \n","\n","Centered MA uses n/2-1 steps back, the cuttent value and n/2-1 steps ahead"],"metadata":{"id":"3hCDdkbjnfK4"}},{"cell_type":"markdown","source":["##5.7\n","Use TensorFlow for forecasting.\n"],"metadata":{"id":"Dg3gaW4RP9k4"}},{"cell_type":"code","source":["def make_preds(model, input_data):\n","  \"\"\"\n","  Uses model to make predictions on input_data.\n","\n","  Parameters\n","  ----------\n","  model: trained model \n","  input_data: windowed input data (same kind of data model was trained on)\n","\n","  Returns model predictions on input_data.\n","  \"\"\"\n","  forecast = model.predict(input_data)\n","  return tf.squeeze(forecast) # return 1D array of predictions"],"metadata":{"id":"J0BMx05meEh7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##5.8\n","Prepare features and labels.\n"],"metadata":{"id":"j1BmId-SP_wI"}},{"cell_type":"markdown","source":["You can use padas DF or even list, but when you are facing problems that requires complex architecture the best tool is tf.data.Dataset.from_tensor_slices for composing heterogeneous train dataset and labels then combine them using tf.data.Dataset.zip"],"metadata":{"id":"2hj7pt0RtoGH"}},{"cell_type":"markdown","source":["##5.9\n","Identify and compensate for sequence bias.\n"],"metadata":{"id":"yZbRnYW8QB8n"}},{"cell_type":"markdown","source":["##5.10\n","Adjust the learning rate dynamically in time series, sequence and prediction models."],"metadata":{"id":"HWsmqemmQExY"}},{"cell_type":"markdown","source":["See the callback tf.keras.callbacks.ReduceLROnPlateau in the  previous point"],"metadata":{"id":"eupbsimcK_LN"}}]}